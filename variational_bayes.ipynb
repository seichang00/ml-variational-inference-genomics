{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Inference in Pyro on CIFAR 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-Processing\n",
    "\n",
    "#### Unwrapping CIFAR 10 Python Dataset\n",
    "\n",
    "CIFAR-10 contains 60K 32x32 images divided into 10 clusters. \n",
    "- `test_batch` contains 10K samples.\n",
    "- `data_batch_{1...5}` contains 10K samples each, amounting to total of 50K samples.\n",
    "- `batches.meta` contains information on the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./cifar-10-batches-py/batches.meta\n",
      "dict_keys(['num_cases_per_batch', 'label_names', 'num_vis'])\n",
      "./cifar-10-batches-py/data_batch_1\n",
      "dict_keys(['batch_label', 'labels', 'data', 'filenames'])\n",
      "./cifar-10-batches-py/data_batch_2\n",
      "dict_keys(['batch_label', 'labels', 'data', 'filenames'])\n",
      "./cifar-10-batches-py/data_batch_3\n",
      "dict_keys(['batch_label', 'labels', 'data', 'filenames'])\n",
      "./cifar-10-batches-py/data_batch_4\n",
      "dict_keys(['batch_label', 'labels', 'data', 'filenames'])\n",
      "./cifar-10-batches-py/data_batch_5\n",
      "dict_keys(['batch_label', 'labels', 'data', 'filenames'])\n",
      "./cifar-10-batches-py/test_batch\n",
      "dict_keys(['batch_label', 'labels', 'data', 'filenames'])\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy\n",
    "\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='latin1')\n",
    "    return dict\n",
    "\n",
    "cifar_path = \"cifar-10-batches-py\"\n",
    "batches = [file for file in sorted(os.listdir(cifar_path)) if \"batch\" in file]\n",
    "\n",
    "data_batches = list()\n",
    "for i, batch in enumerate(batches):\n",
    "    batch_path = os.path.join(os.curdir, cifar_path, batches[i])\n",
    "    data_batches.append(unpickle(batch_path))\n",
    "\n",
    "    print(batch_path)\n",
    "    print(data_batches[i].keys())\n",
    "\n",
    "meta_data = data_batches[0]\n",
    "training_data = data_batches[1:-1]\n",
    "test_data = data_batches[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CIFAR 10 Databatch Breakdown\n",
    "\n",
    "The data entry per databatch contains a 10000K samples x 3072 array. 3072 corresponds to each 32x32 color image, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['airplane',\n",
       " 'automobile',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'deer',\n",
       " 'dog',\n",
       " 'frog',\n",
       " 'horse',\n",
       " 'ship',\n",
       " 'truck']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cases_per_batch = meta_data['num_cases_per_batch']\n",
    "num_vis = meta_data['num_vis']\n",
    "label_names = meta_data['label_names']\n",
    "label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "51dc9f1ff6e0157435cdd11566ea2ea155b14fc128ee776f50901b81d69a36e0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
